{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlcIrqyZQpOo"
      },
      "source": [
        "## Pytorch Model to classify image. \n",
        "- 10 classes. \n",
        "- Training done on MNIST data using 2D CNN.\n",
        "- model performance not tuned; solely for testing AI engineering setup only. \n",
        "\n",
        "reference: \n",
        "https://github.com/pytorch/examples/blob/master/mnist/main.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88uqs51RQoTk"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import numpy as np"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BArkUU4Dwmfg",
        "outputId": "b08f9761-7a63-40e1-9dea-ce4bda0a97af"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGiRgDO-Q7jR"
      },
      "source": [
        "# build model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc2(x)\n",
        "        output = F.log_softmax(x, dim=1)\n",
        "        return output"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EELAZk4mQ9F4"
      },
      "source": [
        "# train model\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "              100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQZrDIY4RMZE"
      },
      "source": [
        "# test model\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uk0xmKG-bv73"
      },
      "source": [
        "# dataset\n",
        "def get_dataset():\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])\n",
        "    train_data = datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transform)\n",
        "    test_data = datasets.MNIST('../data', train=False,\n",
        "                       transform=transform)\n",
        "    return train_data, test_data"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BXAOdYI6Hau"
      },
      "source": [
        "# get train_loader and test_loader\n",
        "def get_loaders(batch_size, train_data, test_data):\n",
        "    train_kwargs = {'batch_size': batch_size}\n",
        "    test_kwargs = {'batch_size': batch_size}\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        cuda_kwargs = {'num_workers': 1,\n",
        "                       'pin_memory': True,\n",
        "                       'shuffle': True}\n",
        "        train_kwargs.update(cuda_kwargs)\n",
        "        test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_data,**train_kwargs)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, **test_kwargs)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyKyKmEXRP7U"
      },
      "source": [
        "# main function\n",
        "def main(epochs, train_loader, test_loader):\n",
        "    # Training settings\n",
        "    torch.manual_seed(1)\n",
        "    \n",
        "\n",
        "    model = Net().to(device)\n",
        "    optimizer = optim.Adadelta(model.parameters(), lr=0.01)\n",
        "\n",
        "    scheduler = StepLR(optimizer, step_size=1, gamma=0.5)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, optimizer, epoch)\n",
        "        test(model, device, test_loader)\n",
        "        scheduler.step()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PdLvXY5Z43c",
        "outputId": "efe4ed02-c230-498f-84dd-96116c979db5"
      },
      "source": [
        "train_data, test_data = get_dataset()\n",
        "print(train_data)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ../data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.1307,), std=(0.3081,))\n",
            "           )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t02UEPwIRyTa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d5f6541-11a8-4661-e1c2-506a0cc79e9f"
      },
      "source": [
        "# run main\n",
        "batch_size = 250\n",
        "epochs = 20\n",
        "\n",
        "train_loader, test_loader = get_loaders(batch_size, train_data, test_data)\n",
        "\n",
        "model = main(epochs, train_loader, test_loader)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.326382\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 1.195949\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.575605\n",
            "\n",
            "Test set: Average loss: 0.4427, Accuracy: 8879/10000 (89%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.542979\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.633686\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.526757\n",
            "\n",
            "Test set: Average loss: 0.3527, Accuracy: 9064/10000 (91%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.623399\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.467733\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.428579\n",
            "\n",
            "Test set: Average loss: 0.3276, Accuracy: 9097/10000 (91%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.523870\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.429676\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.489012\n",
            "\n",
            "Test set: Average loss: 0.3179, Accuracy: 9134/10000 (91%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.454030\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.448115\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.491389\n",
            "\n",
            "Test set: Average loss: 0.3128, Accuracy: 9143/10000 (91%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.470145\n",
            "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.419357\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.458162\n",
            "\n",
            "Test set: Average loss: 0.3105, Accuracy: 9153/10000 (92%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.534390\n",
            "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.403141\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.447641\n",
            "\n",
            "Test set: Average loss: 0.3095, Accuracy: 9156/10000 (92%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.489551\n",
            "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.445712\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.404802\n",
            "\n",
            "Test set: Average loss: 0.3089, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.375305\n",
            "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.398213\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.414393\n",
            "\n",
            "Test set: Average loss: 0.3087, Accuracy: 9160/10000 (92%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.527844\n",
            "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.369535\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.420548\n",
            "\n",
            "Test set: Average loss: 0.3085, Accuracy: 9160/10000 (92%)\n",
            "\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.524927\n",
            "Train Epoch: 11 [25000/60000 (42%)]\tLoss: 0.505367\n",
            "Train Epoch: 11 [50000/60000 (83%)]\tLoss: 0.406627\n",
            "\n",
            "Test set: Average loss: 0.3085, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.428420\n",
            "Train Epoch: 12 [25000/60000 (42%)]\tLoss: 0.405848\n",
            "Train Epoch: 12 [50000/60000 (83%)]\tLoss: 0.476257\n",
            "\n",
            "Test set: Average loss: 0.3084, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.454968\n",
            "Train Epoch: 13 [25000/60000 (42%)]\tLoss: 0.444087\n",
            "Train Epoch: 13 [50000/60000 (83%)]\tLoss: 0.430469\n",
            "\n",
            "Test set: Average loss: 0.3084, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.487536\n",
            "Train Epoch: 14 [25000/60000 (42%)]\tLoss: 0.420312\n",
            "Train Epoch: 14 [50000/60000 (83%)]\tLoss: 0.405833\n",
            "\n",
            "Test set: Average loss: 0.3084, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.559324\n",
            "Train Epoch: 15 [25000/60000 (42%)]\tLoss: 0.481292\n",
            "Train Epoch: 15 [50000/60000 (83%)]\tLoss: 0.458324\n",
            "\n",
            "Test set: Average loss: 0.3084, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.431254\n",
            "Train Epoch: 16 [25000/60000 (42%)]\tLoss: 0.512398\n",
            "Train Epoch: 16 [50000/60000 (83%)]\tLoss: 0.474090\n",
            "\n",
            "Test set: Average loss: 0.3084, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.478585\n",
            "Train Epoch: 17 [25000/60000 (42%)]\tLoss: 0.423651\n",
            "Train Epoch: 17 [50000/60000 (83%)]\tLoss: 0.443726\n",
            "\n",
            "Test set: Average loss: 0.3084, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.364912\n",
            "Train Epoch: 18 [25000/60000 (42%)]\tLoss: 0.444182\n",
            "Train Epoch: 18 [50000/60000 (83%)]\tLoss: 0.387267\n",
            "\n",
            "Test set: Average loss: 0.3084, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.484386\n",
            "Train Epoch: 19 [25000/60000 (42%)]\tLoss: 0.466250\n",
            "Train Epoch: 19 [50000/60000 (83%)]\tLoss: 0.427229\n",
            "\n",
            "Test set: Average loss: 0.3084, Accuracy: 9161/10000 (92%)\n",
            "\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.519418\n",
            "Train Epoch: 20 [25000/60000 (42%)]\tLoss: 0.454217\n",
            "Train Epoch: 20 [50000/60000 (83%)]\tLoss: 0.476217\n",
            "\n",
            "Test set: Average loss: 0.3084, Accuracy: 9161/10000 (92%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmlgKDoRQ-0S"
      },
      "source": [
        "# save model (typical weights saving, cannot be use for triton)\n",
        "path = \"model_pytorch_mnist.pt\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eb12zws73j_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41a4d65-c90a-4a86-fd77-9e4fa451836d"
      },
      "source": [
        "# printing out summary (not useful)\n",
        "from torchsummary import summary\n",
        "summary(model, (1, 28, 28))\n",
        "print(model)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             320\n",
            "            Conv2d-2           [-1, 64, 24, 24]          18,496\n",
            "           Dropout-3           [-1, 64, 12, 12]               0\n",
            "            Linear-4                  [-1, 128]       1,179,776\n",
            "           Dropout-5                  [-1, 128]               0\n",
            "            Linear-6                   [-1, 10]           1,290\n",
            "================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.52\n",
            "Params size (MB): 4.58\n",
            "Estimated Total Size (MB): 5.10\n",
            "----------------------------------------------------------------\n",
            "Net(\n",
            "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (dropout1): Dropout(p=0.25, inplace=False)\n",
            "  (dropout2): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR_HLMHpk_7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf56de4-bb6d-4471-eee8-9273377cdf6a"
      },
      "source": [
        "# https://medium.com/nvidia-ai/how-to-deploy-almost-any-hugging-face-model-on-nvidia-triton-inference-server-with-an-8ee7ec0e6fc4\n",
        "# saving model based on Torchscript way using tracing. This will be used for Triton.\n",
        "\n",
        "import tensorflow as tf\n",
        "# load a sample image\n",
        "example_img, example_label = next(iter(train_loader))\n",
        "print(example_img.shape)\n",
        "example_img = example_img.to(device)\n",
        "model.to(device)\n",
        "\n",
        "# run the tracing\n",
        "traced_script_model = torch.jit.trace(model, example_img)\n",
        "\n",
        "# see model functions\n",
        "print(traced_script_model.code)\n",
        "\n",
        "# save the converted model\n",
        "path_jit = \"model_pytorch_mnist_jit.pt\"\n",
        "traced_script_model.save(path_jit)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([250, 1, 28, 28])\n",
            "def forward(self,\n",
            "    input: Tensor) -> Tensor:\n",
            "  _0 = self.fc2\n",
            "  _1 = self.dropout2\n",
            "  _2 = self.fc1\n",
            "  _3 = self.dropout1\n",
            "  _4 = self.conv2\n",
            "  input0 = torch.relu((self.conv1).forward(input, ))\n",
            "  input1 = torch.relu((_4).forward(input0, ))\n",
            "  input2 = torch.max_pool2d(input1, [2, 2], annotate(List[int], []), [0, 0], [1, 1], False)\n",
            "  input3 = torch.flatten((_3).forward(input2, ), 1, -1)\n",
            "  input4 = torch.relu((_2).forward(input3, ))\n",
            "  _5 = (_0).forward((_1).forward(input4, ), )\n",
            "  return torch.log_softmax(_5, 1, None)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x5e4lQAmgMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b760cc2-11fe-4a47-a6b1-6b715fc6d39f"
      },
      "source": [
        "# load model with saved weights and infer\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval().to(device)\n",
        "print(\"label: \", model(example_img))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label:  tensor([[-5.0846e+00, -6.5180e+00, -4.0622e+00,  ..., -7.6214e+00,\n",
            "         -4.9520e+00, -9.4501e+00],\n",
            "        [-7.0891e+00, -9.4501e+00, -5.1400e+00,  ..., -6.7569e+00,\n",
            "         -2.1310e+00, -4.8164e+00],\n",
            "        [-1.0334e+01, -7.6493e+00, -5.3049e+00,  ..., -1.0309e+01,\n",
            "         -6.6333e+00, -6.7848e+00],\n",
            "        ...,\n",
            "        [-8.7363e+00, -7.6697e+00, -6.6681e+00,  ..., -1.2061e-02,\n",
            "         -6.0919e+00, -5.2994e+00],\n",
            "        [-1.3476e+01, -1.9415e+01, -1.5138e+01,  ..., -6.8424e-05,\n",
            "         -1.2458e+01, -9.9448e+00],\n",
            "        [-8.4042e+00, -6.5621e-02, -6.8290e+00,  ..., -5.0921e+00,\n",
            "         -3.0381e+00, -6.0528e+00]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8udGwslT5XHP",
        "outputId": "c500d8a4-b69f-4b83-b543-6f56ecd83c13"
      },
      "source": [
        "# infer with traced_script_model\n",
        "print(\"label: \", traced_script_model(example_img))"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label:  tensor([[-5.0846e+00, -6.5180e+00, -4.0622e+00,  ..., -7.6214e+00,\n",
            "         -4.9520e+00, -9.4501e+00],\n",
            "        [-7.0891e+00, -9.4501e+00, -5.1400e+00,  ..., -6.7569e+00,\n",
            "         -2.1310e+00, -4.8164e+00],\n",
            "        [-1.0334e+01, -7.6493e+00, -5.3049e+00,  ..., -1.0309e+01,\n",
            "         -6.6333e+00, -6.7848e+00],\n",
            "        ...,\n",
            "        [-8.7363e+00, -7.6697e+00, -6.6681e+00,  ..., -1.2061e-02,\n",
            "         -6.0919e+00, -5.2994e+00],\n",
            "        [-1.3476e+01, -1.9415e+01, -1.5138e+01,  ..., -6.8424e-05,\n",
            "         -1.2458e+01, -9.9448e+00],\n",
            "        [-8.4042e+00, -6.5621e-02, -6.8290e+00,  ..., -5.0921e+00,\n",
            "         -3.0381e+00, -6.0528e+00]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITHHTOJFCuKq"
      },
      "source": [
        "### Infer with own data; remember to upload your own image and change the path accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEZ8n6AOjxg2"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "# pre-processing\n",
        "def preprocessing():\n",
        "    INPUT_SHAPE = (28, 28)\n",
        "    '''\n",
        "    Return (1, 1, 28, 28) with FP32 input from image\n",
        "    '''\n",
        "    img = Image.open('/content/7.png').convert('L')\n",
        "    img = img.resize(INPUT_SHAPE)\n",
        "    imgArr = np.asarray(img) / 255\n",
        "    imgArr = np.expand_dims(imgArr, 0)\n",
        "    imgArr = np.expand_dims(imgArr, 0)\n",
        "    imgArr = imgArr.astype(np.float32)\n",
        "    print(imgArr.shape)\n",
        "    torch.from_numpy(x).to(device)\n",
        "    return imgArr"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdsBl3Up2fmG",
        "outputId": "9d41b9a8-2bf4-444e-98a9-67addf4f4fd6"
      },
      "source": [
        "# infer with model loaded from saved weights\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(path))\n",
        "model.eval().to(device)\n",
        "print(\"label: \", model(x))\n",
        "print(model(x).shape)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label:  tensor([[-3.2908, -4.8340, -3.2013, -2.5351, -4.1441, -3.7628, -4.4674, -0.3773,\n",
            "         -3.6178, -2.6347]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoV8JBMAjxj1",
        "outputId": "4447690b-f14f-494b-f4cb-7926a06a8978"
      },
      "source": [
        "# predict using traced model\n",
        "prediction = traced_script_model(x)\n",
        "print(\"label: \", prediction)\n",
        "print(prediction.shape)\n",
        "prediction1 = prediction.reshape(10).cpu()\n",
        "print(tf.argmax(prediction1.detach().numpy()))"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label:  tensor([[-3.2908, -4.8340, -3.2013, -2.5351, -4.1441, -3.7628, -4.4674, -0.3773,\n",
            "         -3.6178, -2.6347]], device='cuda:0', grad_fn=<LogSoftmaxBackward>)\n",
            "torch.Size([1, 10])\n",
            "tf.Tensor(7, shape=(), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tCACg2j4BjL"
      },
      "source": [
        "# script for config.pbtxt\n",
        "##TODO\n"
      ],
      "execution_count": 82,
      "outputs": []
    }
  ]
}